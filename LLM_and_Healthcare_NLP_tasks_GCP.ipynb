{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshraju/Aadhar-uidaiBenchmark/blob/master/LLM_and_Healthcare_NLP_tasks_GCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-iLoviv7Zzm"
      },
      "source": [
        "**This notebook demonstrates toy examples of LLM Use cases in Healthcare using  Google PaLM API - GCP. This is an experiment/prototype of ideas not a formal evaluation of the APIs or production code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "javKxQXhbAnN"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3bxNQk7BIjMx",
        "outputId": "707aea28-4bdf-4256-9ad6-2b2efbfa7d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.200-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk>=0.0.9 (from langchain)\n",
            "  Downloading langchainplus_sdk-0.0.9-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.8 langchain-0.0.200 langchainplus-sdk-0.0.9 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.89.0-py2.py3-none-any.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.21.0)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.59.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.27.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
            "Installing collected packages: google-api-python-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "Successfully installed google-api-python-client-2.89.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.26.0-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Collecting google-cloud-storage\n",
            "  Downloading google_cloud_storage-2.9.0-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery[pandas] in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Collecting google-cloud-bigquery[pandas]\n",
            "  Downloading google_cloud_bigquery-3.11.1-py2.py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.4/219.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting redis\n",
            "  Downloading redis-4.5.5-py3-none-any.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.3/240.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scann\n",
            "  Downloading scann-1.2.9-cp310-cp310-manylinux_2_27_x86_64.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.22.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (23.1)\n",
            "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
            "  Downloading google_cloud_resource_manager-1.10.1-py2.py3-none-any.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.3/321.3 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shapely<2.0.0 (from google-cloud-aiplatform)\n",
            "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.17.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.3.2)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[pandas]) (1.54.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[pandas]) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[pandas]) (1.5.3)\n",
            "Requirement already satisfied: pyarrow>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[pandas]) (9.0.0)\n",
            "Requirement already satisfied: db-dtypes<2.0.0dev,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[pandas]) (1.1.1)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from redis) (4.0.2)\n",
            "Collecting tensorflow~=2.11.0 (from scann)\n",
            "  Downloading tensorflow-2.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m770.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scann) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from scann) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.59.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
            "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
            "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->google-cloud-bigquery[pandas]) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (3.8.0)\n",
            "Collecting keras<2.12,>=2.11.0 (from tensorflow~=2.11.0->scann)\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (3.3.0)\n",
            "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-aiplatform)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (67.7.2)\n",
            "Collecting tensorboard<2.12,>=2.11 (from tensorflow~=2.11.0->scann)\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow~=2.11.0->scann)\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.11.0->scann) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->scann) (0.40.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->scann)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->scann) (3.4.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->scann)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->scann) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->scann) (2.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->scann) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->scann) (2.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->scann) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-data-server, shapely, redis, protobuf, keras, google-auth-oauthlib, tensorboard, grpc-google-iam-v1, tensorflow, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, scann, google-cloud-aiplatform\n",
            "\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 google-cloud-aiplatform-1.26.0 google-cloud-bigquery-3.11.1 google-cloud-resource-manager-1.10.1 google-cloud-storage-2.9.0 grpc-google-iam-v1-0.12.6 keras-2.11.0 protobuf-3.19.6 redis-4.5.5 scann-1.2.9 shapely-1.8.5.post1 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.1 tensorflow-estimator-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv\n",
        "!pip install --upgrade langchain\n",
        "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
        "!pip install --upgrade --user google-cloud-aiplatform \\\n",
        "                              google-cloud-storage \\\n",
        "                             'google-cloud-bigquery[pandas]' \\\n",
        "                              redis \\\n",
        "                              scann"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y774ntTUa855"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDtybrsz7hV7"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kpV8WDb7UTU",
        "outputId": "0bc1448d-c433-4dcb-e2de-285ef6f515e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d3yMoG_7GV_"
      },
      "outputs": [],
      "source": [
        "#Autneticate notebook environment. Required for Google Cloud\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvYN-OSCmfkQ",
        "outputId": "6f651608-e4bf-4955-c1a0-60d5523dac8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "# GCP Project Configs\n",
        "\n",
        "PROJECT_ID = \"useful-maxim-378604\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}\n",
        "\n",
        "REGION = \"us-central1\"   # @param {type: \"string\"}\n",
        "\n",
        "LOCATION = \"US\"  # @param {type: \"string\"}  BigQuery location"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d-kDqEZa4d6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MExwX-p9Gdnd"
      },
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.colab import data_table\n",
        "client = bigquery.Client(project=PROJECT_ID, location=LOCATION)\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "# You may not need all the data sources . Choose whatever data source you want to use\n",
        "\n",
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel,\\\n",
        "                                            ChatModel,\\\n",
        "                                            InputOutputTextPair,\\\n",
        "                                            TextEmbeddingModel\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5xnScb9m-UM"
      },
      "outputs": [],
      "source": [
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgKtMBGKD3St"
      },
      "outputs": [],
      "source": [
        "completions_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0DCO8ONDymh"
      },
      "outputs": [],
      "source": [
        "# Helper function to call the model API\n",
        "# For Healthcare NLP tasks you may run into token limit as clinical notes are long.\n",
        "\n",
        "def get_completion(prompt, model, temperature, max_output_tokens):\n",
        "    response = model.predict(\n",
        "        prompt=prompt,\n",
        "        temperature= temperature,\n",
        "        max_output_tokens = max_output_tokens,\n",
        "    )\n",
        "    content = response.text\n",
        "    return content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBK3P7xbZC-1"
      },
      "source": [
        "# Use Case #1 - NLP entity and context extractions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYUPlLpOE8o5"
      },
      "source": [
        "# Chain of Thought Reasoning to provide additional context in the NLP extractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "522rLYbpxWoj"
      },
      "outputs": [],
      "source": [
        "text = f\"\"\"\n",
        " The patient is a 17-year-old female, who presents to the emergency room with foreign body and airway compromise and was taken to the operating room.  She was intubated and fishbone.\n",
        " \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hym-IfPhtwRq"
      },
      "outputs": [],
      "source": [
        "context = f\"\"\"\n",
        "You are a Healthcare AI Assistant helping to extract entities and context from clinical text using the guidance stated below:\n",
        "1 - Entity Recognition: You will have entity categories: Person, Location, Age,Gender, Disease/Problem, Anatomical Structure,Symptoms,Procedure, Medications,\\\n",
        "Medical Devices, Lab Test, Substance Abuse, Social Determinants.\n",
        "\n",
        "2 - Entity Assertions: Probability of Assertions in extracted entities.Classify the assertions made on given medical concepts as being present, absent,\n",
        "or possible in the patient, conditionally present in the patient under certain circumstances, hypothetically present in the patient at some future point,\\\n",
        "and mentioned in the patient report but associated with someone other than the patient.In addition, perform Subject Asssessment. Differentiate between \\\n",
        "\"Patient\" Vs. \" Family Member\" in the text description.\n",
        "For example: \"John's father has diabetes\". Attach \"diabetes\" to assertion status: Family Member'\n",
        "Assertion Status: 1. Present, 2. Absent, 3. Possible, 4. Hypothetical, 5. Conditional, 6. Family\n",
        "\n",
        "3 - Temporal Assessment: Extract Date or Temporality of the entity and use these categorization:\n",
        "    Extract Actual Date if date is available in the text.\n",
        "In case where date is not available, assess temporality and categorize as:\n",
        "1. Current\n",
        "2. History\n",
        "3. Actual Date if date is available in the text\n",
        "\n",
        "Input Data: A 60 year old male with a history of type-2 diabetes, diagnosed 10 years ago, takes 500 mg metformmin.\n",
        "Output:\n",
        "{\n",
        "    {\n",
        "      \"Name\": \"60-year-old\",\n",
        "      \"Category\": \"Demographic Entity\",\n",
        "      \"Assertion Status\": \"Present\",\n",
        "      \"Temporality\": \"Current\"\n",
        "    },\n",
        "    {\n",
        "      \"Name\": \"male\",\n",
        "      \"Category\": \"Demographic Entity\",\n",
        "      \"Assertion Status\": \"Present\",\n",
        "      \"Temporality\": \"Current\"\n",
        "    },\n",
        "    {\n",
        "      \"Name\": \"type-2 diabetes\",\n",
        "      \"Category\": \"Disease/Problem\",\n",
        "      \"Assertion Status\": \"Present\",\n",
        "      \"Temporality\": \"10 years ago\"\n",
        "    },\n",
        "    {\n",
        "      \"Name\": \"metformin\",\n",
        "      \"Category\": \"medication\",\n",
        "      \"Assertion Status\": \"Present\",\n",
        "      \"Temporality\": \"Current\"\n",
        "    },\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w09sfGcHQx5"
      },
      "source": [
        "# Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHE35FRKYOdu"
      },
      "outputs": [],
      "source": [
        "# Initialize a prompt.\n",
        "prompt = f\"\"\"\n",
        "Perform the following actions. Lets think step by step and use the guidance provided. Take your time and try to answer accurately.\n",
        "1 -  Extract entity name, category, assertion status, and temporality\n",
        "2 - Output the json object that contains the following keys: entity name, category, assertion status, temporality.\n",
        "If the question cannot be answered using the information provided answer with “No entities found”\n",
        "Context:{context}\n",
        "text: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7rsPe7twxJ8"
      },
      "source": [
        "# System Response: NLP Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_bhhjgVNtzX",
        "outputId": "b3cd002b-398e-4b4b-c539-6a7d6b596e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "({'Name': '17-year-old', 'Category': 'Demographic Entity', 'Assertion Status': 'Present', 'Temporality': 'Current'}, {'Name': 'female', 'Category': 'Demographic Entity', 'Assertion Status': 'Present', 'Temporality': 'Current'}, {'Name': 'foreign body', 'Category': 'Symptom', 'Assertion Status': 'Present', 'Temporality': 'Current'}, {'Name': 'airway compromise', 'Category': 'Symptom', 'Assertion Status': 'Present', 'Temporality': 'Current'}, {'Name': 'operating room', 'Category': 'Location', 'Assertion Status': 'Present', 'Temporality': 'Current'}, {'Name': 'intubated', 'Category': 'Procedure', 'Assertion Status': 'Present', 'Temporality': 'Current'}, {'Name': 'fishbone', 'Category': 'Anatomical Structure', 'Assertion Status': 'Present', 'Temporality': 'Current'})\n"
          ]
        }
      ],
      "source": [
        "temperature = 0.2  # To make the output more deterministic\n",
        "max\n",
        "assistant_response = get_completion(prompt, completions_model, temperature, 1024)\n",
        "print(assistant_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6fkqOao4wex"
      },
      "source": [
        "# Use Case #2: Write SOAP Notes from Patient-Clinician Conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCbF7k2-5aki"
      },
      "outputs": [],
      "source": [
        "# Set the context\n",
        "\n",
        "context = f\"\"\"\n",
        "You are a Healthcare AI Assistant helping to write SOAP Notes from the conversation text.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaVugQvb4cUs"
      },
      "outputs": [],
      "source": [
        "# Input Data\n",
        "\n",
        "conversation_1 = f\"\"\"\n",
        "Hi, how's it going?    I'm not feeling well today. I have some abdominal pain.     I'm sorry to hear that.  Can you tell me a little bit about that? Yes, I have had some pain for the last two weeks, in the mid abdomen, going to the lower abdomen. Have you had any nausea or vomiting or diarrhea? Yes, I've had some diarrhea. Anybody else at home that sick? Well, my husband and my son are also sick with some diarrhea and abdominal pain. Do you have any fevers? No, I don't have any fevers or chills. OK let's take a look and examine you.\n",
        "Well, I think you might have some gastroenteritis,  And infection of the abdomen just caused by food poisoning. I think if you drink plenty of water, and stick to a brat diet, it should pass. However, if it still lingers after several days, I think we need to run some tests. How does that sound? Thank you doctor, that sounds like a plan .\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H12D7z6X5SCO"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Perform the following actions. Lets think step by step and use the guidance provided. Take your time and try to answer accurately.\n",
        "1 - Create SOAP Note from Patient-docto conversation\n",
        "context: {context}\n",
        "text: {conversation_1}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gwdopvQ5HPD",
        "outputId": "168b1072-1256-4eb0-8ab4-02046712a17f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**S**ubjective: Patient presents with a 2-week history of abdominal pain. The pain is located in the mid-abdomen and radiates to the lower abdomen. The pain is worse after eating and is associated with nausea, vomiting, and diarrhea. The patient denies fevers or chills.\n",
            "\n",
            "**O**bjective: Vital signs are within normal limits. Abdominal exam reveals tenderness in the mid-abdomen and lower abdomen. There is no rebound tenderness or guarding.\n",
            "\n",
            "**A**ssessment: Gastroenteritis\n",
            "\n",
            "**P**lan: Patient is advised to drink plenty of fluids and stick to a BRAT diet (bananas, rice, applesauce, and toast). The patient is also given a prescription for loperamide to help with the diarrhea. The patient is instructed to follow up with the doctor if the symptoms do not improve after several days.\n"
          ]
        }
      ],
      "source": [
        "temperature = 0.2  # Allow for little creativity\n",
        "assistant_response = get_completion(prompt, completions_model, temperature, 1024)\n",
        "print(assistant_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArA6BWod91Nh"
      },
      "source": [
        "# Use Case # 3: Summarize a Biomedical Research Article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-f4hDCc-H2J"
      },
      "outputs": [],
      "source": [
        "abstract = \"\"\"\n",
        "Sepsis-associated acute kidney injury (S-AKI) is a frequent complication of the critically ill patient and is associated with unacceptable morbidity and mortality.\\\n",
        "Prevention of S-AKI is difficult because by the time patients seek medical attention, most have already developed acute kidney injury. Thus, early recognition is crucial \\\n",
        "to provide supportive treatment and limit further insults. Current diagnostic criteria for acute kidney injury has limited early detection; however, novel biomarkers \\\n",
        "of kidney stress and damage have been recently validated for risk prediction and early diagnosis of acute kidney injury in the setting of sepsis. Recent evidence shows \\\n",
        "that microvascular dysfunction, inflammation, and metabolic reprogramming are 3 fundamental mechanisms that may play a role in the development of S-AKI. \\\n",
        "However, more mechanistic studies are needed to better understand the convoluted pathophysiology of S-AKI and to translate these findings into potential treatment strategies \\\n",
        "and add to the promising pharmacologic approaches being developed and tested in clinical trials.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lhGAoah-N3L"
      },
      "outputs": [],
      "source": [
        "# Set the context\n",
        "context = f\"\"\"\n",
        "You are an Healthcare AI Assistant helping to summarize biomedical artciles related to Acute Kidney Injury.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlJwJFIH-cQH"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a medical article \\\n",
        "abstract from pubmed site.\n",
        "1 - Summarize the abstract below,in at most 20 words focusing on AKI prediction and treatment options.\n",
        "2 - List the major topics discussed in the article. Classify the topics into:\n",
        "    a. disease, b. symptom, c. procedure, d.medication.\n",
        "article:{abstract}\n",
        "context: {context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ni-C1Us_IyW",
        "outputId": "489b99fe-d0b4-4a09-8a6a-d5d3cd71373b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 - Sepsis-associated acute kidney injury is a frequent complication of the critically ill patient. Novel biomarkers and therapeutic strategies are being developed to prevent and treat S-AKI.\n",
            "2 - Topics:\n",
            "    a. Disease: Acute kidney injury, sepsis\n",
            "    b. Symptom: Acute kidney injury\n",
            "    c. Procedure: Biomarkers\n",
            "    d. Medication: None\n"
          ]
        }
      ],
      "source": [
        "temperature = 0.2  # Allow for little creativity\n",
        "assistant_response = get_completion(prompt, completions_model, temperature, 1024)\n",
        "print(assistant_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmCCKzZ5XKxd"
      },
      "source": [
        "# Use Case # 4: Summarize a Patient's Medical Record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK4now1AXWiS"
      },
      "outputs": [],
      "source": [
        "clinical_text = f\"\"\"\n",
        "Plan:\n",
        "CKD (Serology): due to likely hyperfiltration syndrome (patient drinking 2 gallons of water),- improved creatinine\n",
        "-I warned the patient about hyperfiltration syndrome.  The patient is drinking way too much liquid, and may be causing worsening of his renal function, because of hyperfiltration syndrome.\n",
        "- he needs to limit his fluid intake to 2L, a bit more if he exercises and sweats\n",
        "- his blood pressure and blood sugar are decently controlled now\n",
        "\n",
        "Proteinuria:   well controlled\n",
        "- protein restriction discussed\n",
        "- on ACE inhibitor or angiotensin receptor blocker: yes\n",
        "\n",
        "Blood Pressure:  well controlled\n",
        "- low salt diet\n",
        "- current treatment plan is effective, no change in therapy Diabetes/[Synop]: stable Continue current plan. Review blood glucose monitoring. Discuss risks of poor blood glucose control. Review carbohydrate-controlled diet.\n",
        "\n",
        "Preventative: HMM  Care Gap SS  Check labs now Follow up with me in 3 months\n",
        "Cc to Medical assistant\n",
        "=============================================================  SUBJECTIVE\n",
        "\n",
        "John Smith is a male with diabetes mellitus 2, hypertension, bph, hyperlipidemia, aaa, high bmi, CAD/CABG, AF on coumadin, copd, anemia, osa, mdd, gerd, moderate chronic renal failure for month(s) who comes to see me for a follow up visit.  Patient says that he drinks about 2 gallons a day. Because his mouth is really dry.\n",
        "\n",
        "Lab Results  Component\n",
        "Value\n",
        "Date  Creatinine\n",
        "2.25 (H)\n",
        "04/11/2023  Creatinine\n",
        "2.08 (H)\n",
        "04/02/2023  Creatinine\n",
        "2.34 (H)\n",
        "04/01/2023   ROS: + frequency - urgency + dysuria - hematuria - skin changes/rash + joint pains; takes tylenol  - sinus problems - epistaxis - cough with blood + stone history; many years ago x 4, last 1969 + urinary hesitancy + nocturia: 2 times a nigth  + leg edema - little in the left leg  - NSAID use    Reviewed: medical history with no changes 5/12/2023, social history with no changes  5/12/2023 and family history with no changes 5/12/2023      PHYSICAL EXAM\n",
        "     BP Readings from Last 3 Encounters:\n",
        "05/12/23  103/55\n",
        "04/07/23  101/54\n",
        "04/02/23  132/72\n",
        "     Pulse Readings from Last 3 Encounters:\n",
        "05/12/23  80\n",
        "04/07/23  69\n",
        "04/02/23  72\n",
        "     Wt Readings from Last 3 Encounters:\n",
        "05/12/23  116.9 kg (257 lb 11.2 oz)\n",
        "04/07/23  115.7 kg (255 lb)\n",
        "04/02/23  123.8 kg (273 lb)\n",
        "     BMI Readings from Last 3 Encounters:\n",
        "05/12/23  39.18 kg/m²\n",
        "04/07/23  38.77 kg/m²\n",
        "04/02/23  41.51 kg/m²\n",
        "  General appearance - oriented to person, place, and time Chest - clear Heart - S1 and S2 normal Abdomen - soft Extremities - pedal edema: 0 +     RESULTS\n",
        "Data Reviewed:  Reviewed lab results: Renal:       Lab Results\n",
        "Component  Value  Date\n",
        "   Estimated Glomerular Filtration Rate  29 (L)  04/11/2023\n",
        "   Estimated Glomerular Filtration Rate  24 (L)  03/31/2023\n",
        "   Estimated Glomerular Filtration Rate  35 (L)  11/23/2022\n",
        "         Lab Results\n",
        "Component  Value  Date\n",
        "   Creatinine  2.25 (H)  04/11/2023\n",
        "   Creatinine  2.08 (H)  04/02/2023\n",
        "   Creatinine  2.34 (H)  04/01/2023\n",
        "   Creatinine  2.63 (H)  03/31/2023\n",
        "   Creatinine  1.94 (H)  11/23/2022\n",
        "         Lab Results\n",
        "Component  Value  Date\n",
        "   BUN  29 (H)  04/02/2023\n",
        "      Anemia:       Lab Results\n",
        "Component  Value  Date\n",
        "   Hgb  11.5 (L)  04/02/2023\n",
        "   Hgb  11.5 (L)  04/01/2023\n",
        "   Hematocrit  37.1 (L)  04/02/2023\n",
        "   Hematocrit  36.3 (L)  04/01/2023\n",
        "   MCV  90  04/02/2023\n",
        "   MCV  89  04/01/2023\n",
        "   Transferrin % saturation  37  11/23/2022\n",
        "   Transferrin % saturation  7 (L)  11/22/2016\n",
        "    Bone:       Lab Results\n",
        "Component  Value  Date\n",
        "   Calcium  8.7 (L)  03/31/2023\n",
        "         Lab Results\n",
        "Component  Value  Date\n",
        "   Phosphorus  3.5  03/31/2023\n",
        "   No results found for: PTHINTACT No results found for: VITD25    Potassium:       Lab Results\n",
        "Component  Value  Date\n",
        "   Potassium  5.0  04/11/2023\n",
        "   Potassium  4.5  04/02/2023\n",
        "   Potassium  4.2  04/01/2023\n",
        "    Protein:      Lab Results\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPfy1aJ9Xts3"
      },
      "outputs": [],
      "source": [
        "# Set the context\n",
        "context = f\"\"\"\n",
        "You are an Healthcare AI Assistant helping to summarize patient's situation from medical history.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJSWc8kZX4lw"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of patient's medical record \\\n",
        "medical record:{clinical_text}\n",
        "context:{context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Xr-ypTX-ji",
        "outputId": "4461e2df-7732-47fa-b25f-962e7d819b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The patient is a 72-year-old male with a history of diabetes mellitus type 2, hypertension, bph, hyperlipidemia, aaa, high bmi, cad/cabg, af on coumadin, copd, anemia, osa, mdd, gerd, moderate chronic renal failure for month(s) who comes to see me for a follow up visit.  Patient says that he drinks about 2 gallons a day. Because his mouth is really dry. \n",
            "\n",
            "The patient's blood pressure is well controlled. His blood sugar is also well controlled. His creatinine is elevated, but it is stable. His potassium is also elevated, but it is stable. His hemoglobin is low, but it is stable. His hematocrit is low, but it is stable. His mcv is low, but it is stable. His transferrin % saturation is low, but it is stable. His calcium is normal. His phosphorus is normal. His potassium is normal. His protein is normal.\n"
          ]
        }
      ],
      "source": [
        "temperature = 0.2  # Allow for little creativity\n",
        "assistant_response = get_completion(prompt, completions_model, temperature, 1024)\n",
        "print(assistant_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9mZgDAkDBmr"
      },
      "source": [
        "# Evaluate the LLM's answer based on \"expert\" human generated answer. Work in Progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op67-Sw0-Daw"
      },
      "outputs": [],
      "source": [
        "# This is a evaluation framework, I still have to work with MIMIC data to create the test.\n",
        "# Source https://github.com/openai/evals/blob/main/evals/registry/modelgraded/fact.yaml\n",
        "\n",
        "def eval_with_ideal(test_set, assistant_answer):\n",
        "\n",
        "    test_input = test_set['note']\n",
        "    test_output = test_set['entity_list']\n",
        "    llm_answer = assistant_answer\n",
        "\n",
        "    system_message = \"\"\"\\\n",
        "    You are an assistant that evaluates how well the data processing assistant \\\n",
        "    extracts entities by looking at the context that the customer service \\\n",
        "    agent is using to generate its response.\n",
        "    \"\"\"\n",
        "\n",
        "    user_message = f\"\"\"\\\n",
        "You are evaluating a submitted answer to a question based on the context \\\n",
        "that the agent uses to answer the question.\n",
        "Here is the data:\n",
        "    [BEGIN DATA]\n",
        "    ************\n",
        "    [Input]: {test_input}\n",
        "    ************\n",
        "    [Expert Output]: {test_output}\n",
        "    ************\n",
        "    [Submission]: {llm_answer}\n",
        "    ************\n",
        "    [END DATA]\n",
        "\n",
        "Compare the factual content of the submitted answer with the expert answer. Ignore any differences in style, grammar, or punctuation.\n",
        "    The submitted answer may either be a subset or superset of the expert answer, or it may conflict with it. Determine which case applies. Answer the question by selecting one of the following options:\n",
        "    (A) The submitted answer is a subset of the expert answer and is fully consistent with it.\n",
        "    (B) The submitted answer is a superset of the expert answer and is fully consistent with it.\n",
        "    (C) The submitted answer contains all the same details as the expert answer.\n",
        "    (D) There is a disagreement between the submitted answer and the expert answer.\n",
        "    (E) The answers differ, but these differences don't matter from the perspective of factuality.\n",
        "  choice_strings: ABCDE\n",
        "\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system_message},\n",
        "        {'role': 'user', 'content': user_message}\n",
        "    ]\n",
        "\n",
        "    response = get_completion(messages, completions_model, temperature=0, max_tokens=4096)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZDszchTeb4U"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}